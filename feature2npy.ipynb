{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4057,
     "status": "ok",
     "timestamp": 1652029919193,
     "user": {
      "displayName": "김주엽",
      "userId": "06751949334461059175"
     },
     "user_tz": -540
    },
    "id": "KuEQxQC0gs5d"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from numpy import prod\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, concatenate, Dropout, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"  # Set the GPU 2 to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1652029919563,
     "user": {
      "displayName": "김주엽",
      "userId": "06751949334461059175"
     },
     "user_tz": -540
    },
    "id": "uhxxTg-pgyLx"
   },
   "outputs": [],
   "source": [
    "def preprocess(location, save_path, file_name):\n",
    "    base = tf.keras.applications.MobileNetV3Small(input_shape=(IMG_SIZE, IMG_SIZE, 3), weights='imagenet', include_top=False)\n",
    "    features = np.empty((0, 28224))\n",
    "    labels = []\n",
    "    base_model = tf.keras.Sequential([\n",
    "      base,\n",
    "      Flatten()\n",
    "    ])\n",
    "    base_model.summary()\n",
    "    base_model.trainable = False\n",
    "    index = 0\n",
    "    label = location[-1]\n",
    "    for lb, i in enumerate(os.listdir(location)): #location = new_datasets/train/1\n",
    "        filedir = os.path.join(location, i)\n",
    "        for j in os.listdir(filedir):\n",
    "            split_video = os.path.join(filedir, j)\n",
    "            frames = np.array(list(map(lambda x: os.path.join(split_video, x), os.listdir(split_video))))\n",
    "            frames = sorted(frames, key=lambda x: int(x.split(\"/\")[-1].strip(\".png\")))\n",
    "\n",
    "            if len(frames) > 3000:\n",
    "                print(\"frames over : \", len(frames))\n",
    "                n = len(frames) - 3000\n",
    "                n = n//2\n",
    "                frames = frames[n:-n]\n",
    "                \n",
    "            cutline = len(frames) % LSTM_INTERVAL\n",
    "            if cutline:\n",
    "                frames = frames[:-cutline]\n",
    "            \n",
    "            if os.path.isfile(save_path+'/'+file_name+'_'+str(index)+'.npy'):\n",
    "                index+=len(frames)//45\n",
    "                continue\n",
    "            labels.append([label]*(len(frames)))\n",
    "            frames = np.array(list(map(cv2.imread, frames)))\n",
    "            frames = np.array(list(map(lambda x: cv2.resize(x, (IMG_SIZE, IMG_SIZE)), frames)))\n",
    "\n",
    "            if len(frames) <45:\n",
    "                continue\n",
    "\n",
    "            feature_list = base_model.predict(frames)\n",
    "            for ind in range(0, len(feature_list), 45):\n",
    "\n",
    "                np.save(save_path+'/'+file_name+'_'+str(index)+'.npy',feature_list[ind:ind+45])\n",
    "                index+=1\n",
    "        print(\"doing\", index)\n",
    "        if index > 6000:\n",
    "            break\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_INTERVAL = 45\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 11:49:58.500061: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-16 11:49:58.937032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10157 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:68:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " MobilenetV3small (Functiona  (None, 7, 7, 576)        939120    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28224)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 939,120\n",
      "Trainable params: 927,008\n",
      "Non-trainable params: 12,112\n",
      "_________________________________________________________________\n",
      "frames over :  9065\n",
      "doing 66\n",
      "frames over :  7777\n",
      "doing 132\n",
      "frames over :  6714\n",
      "doing 198\n",
      "frames over :  6911\n",
      "doing 264\n",
      "frames over :  9041\n",
      "doing 330\n",
      "frames over :  9389\n",
      "doing 396\n",
      "frames over :  8750\n",
      "doing 462\n",
      "frames over :  9184\n",
      "doing 528\n",
      "frames over :  9038\n",
      "doing 594\n",
      "frames over :  5460\n",
      "doing 660\n",
      "frames over :  4037\n",
      "doing 726\n",
      "frames over :  5340\n",
      "doing 792\n",
      "frames over :  5191\n",
      "doing 858\n",
      "frames over :  8958\n",
      "doing 924\n",
      "frames over :  7624\n",
      "doing 990\n",
      "frames over :  8801\n",
      "doing 1056\n",
      "frames over :  8824\n",
      "doing 1122\n",
      "frames over :  7387\n",
      "doing 1188\n",
      "frames over :  9047\n",
      "doing 1254\n",
      "frames over :  8954\n",
      "doing 1320\n",
      "frames over :  7378\n",
      "doing 1386\n",
      "frames over :  8562\n",
      "doing 1452\n",
      "frames over :  9560\n",
      "doing 1518\n",
      "frames over :  9482\n",
      "doing 1584\n",
      "frames over :  8849\n",
      "doing 1650\n",
      "frames over :  6685\n",
      "doing 1716\n",
      "frames over :  4484\n",
      "doing 1782\n",
      "frames over :  6718\n",
      "doing 1848\n",
      "frames over :  7454\n",
      "doing 1914\n",
      "frames over :  8160\n",
      "doing 1980\n",
      "frames over :  6603\n",
      "doing 2046\n",
      "frames over :  7127\n",
      "doing 2112\n",
      "frames over :  7145\n",
      "doing 2178\n",
      "frames over :  9006\n",
      "doing 2244\n",
      "frames over :  9526\n",
      "doing 2310\n",
      "frames over :  6674\n",
      "doing 2376\n",
      "frames over :  9370\n",
      "doing 2442\n",
      "frames over :  7097\n",
      "doing 2508\n",
      "frames over :  5193\n",
      "doing 2574\n",
      "frames over :  9012\n",
      "doing 2640\n",
      "frames over :  5368\n",
      "doing 2706\n",
      "frames over :  6661\n",
      "doing 2772\n",
      "frames over :  6832\n",
      "doing 2838\n",
      "frames over :  10786\n",
      "doing 2904\n",
      "frames over :  6999\n",
      "doing 2970\n",
      "frames over :  4967\n",
      "doing 3036\n",
      "frames over :  8332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-16 11:54:20.285272: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8201\n",
      "2022-05-16 11:54:20.533384: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing 3102\n",
      "frames over :  8798\n",
      "doing 3168\n",
      "frames over :  8777\n",
      "doing 3234\n",
      "frames over :  7490\n",
      "doing 3300\n",
      "frames over :  9203\n",
      "doing 3366\n",
      "frames over :  8329\n",
      "doing 3432\n",
      "frames over :  6843\n",
      "doing 3498\n",
      "frames over :  6686\n",
      "doing 3564\n",
      "frames over :  9172\n",
      "doing 3630\n",
      "frames over :  7738\n",
      "doing 3696\n",
      "frames over :  4880\n",
      "doing 3762\n",
      "frames over :  6720\n",
      "doing 3828\n",
      "frames over :  9372\n",
      "doing 3894\n",
      "frames over :  6613\n",
      "doing 3960\n",
      "frames over :  7074\n",
      "doing 4026\n",
      "frames over :  9183\n",
      "doing 4092\n",
      "doing 4155\n",
      "frames over :  7233\n",
      "doing 4221\n",
      "frames over :  6376\n",
      "doing 4287\n",
      "frames over :  5918\n",
      "doing 4353\n",
      "frames over :  8685\n",
      "doing 4419\n",
      "frames over :  9255\n",
      "doing 4485\n",
      "frames over :  6624\n",
      "doing 4551\n",
      "frames over :  4747\n",
      "doing 4617\n",
      "frames over :  9171\n",
      "doing 4683\n",
      "frames over :  7341\n",
      "doing 4749\n",
      "frames over :  6625\n",
      "doing 4815\n",
      "frames over :  8620\n",
      "doing 4881\n",
      "frames over :  8026\n",
      "doing 4947\n",
      "frames over :  8936\n",
      "doing 5013\n",
      "frames over :  7490\n",
      "doing 5079\n",
      "frames over :  6589\n",
      "doing 5145\n",
      "frames over :  6742\n",
      "doing 5211\n",
      "frames over :  7813\n",
      "doing 5277\n",
      "frames over :  8140\n",
      "doing 5343\n",
      "frames over :  9066\n",
      "doing 5409\n",
      "frames over :  7875\n",
      "doing 5475\n",
      "frames over :  6206\n",
      "doing 5541\n",
      "frames over :  9011\n",
      "doing 5607\n",
      "frames over :  8446\n",
      "doing 5673\n",
      "frames over :  8804\n",
      "doing 5739\n",
      "frames over :  7500\n",
      "doing 5805\n",
      "frames over :  6192\n",
      "doing 5871\n",
      "frames over :  5389\n",
      "doing 5937\n",
      "frames over :  6707\n",
      "doing 6003\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "location = \"new_datasets/train/2\"\n",
    "save_path = \"/home/nplab/Jueon/LSTM/final_datasets/train/2\"\n",
    "file_name = 'features_train_normal'\n",
    "preprocess(location, save_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNkJp2QJUm7I2JE2mLAz39U",
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
